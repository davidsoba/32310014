---
title: "Taller 3"
subtitle: "Análisis Avanzado de Datos"
author: "Geraldine Home Saenz - Jose David Soba Loaiza"
date: "2024-05-17"
output: rmdformats::downcute
bibliography: referencias.bib
link-citations: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message=FALSE, warning=FALSE}
# Librerías
library(tidyverse)
library(readxl)
library(ROCR)
library(mice)
```

# Problema 1

Una familia de distribuciones $P_\theta$ con $\theta \in \Theta$ pertenece a la familia exponencial de distribuciones si si fmp/fdp puede escribirse como:

$$p(x|\eta)=h(x)\exp\left(\eta(\theta)t(x)-a(\theta)\right)$$

Para funciones reales $h(x)$, $a(\theta)$ y $t(x)$. Muestre que tanto la distribución Bernoulli (utilizada para la regresión logística), la distribución normal (utilizada en la regresión lineal) y la distribución Poisson (utilizada en la regresión Poisson sobre conteos) pertenece a esta familia de distribuciones.

Tomado de: [@bib01].

## Distribución Bernoulli

La distribución Bernoulli es una distribución de probabilidad discreta que toma el valor 1 con probabilidad $\theta$ y el valor $0$ con probabilidad $(1-\theta)$. La función de masa de probabilidad (fmp) de esta distribución se puede expresar como:

$$p(x|\theta)=\binom{n}{x}\theta^x(1-\theta)^{n-x}; x = 0,1,...,n$$

$$p(x|\theta)=\binom{n}{x}\exp\left(log\left(\frac{\theta}{1-\theta}\right)x+nlog(1-\theta)\right)$$

Donde:

- $h(x)=\binom{n}{x}$

- $\eta(\theta)=log\left(\frac{\theta}{1-\theta}\right)$

- $t(x)=x$

- $a(\theta)=nlog(1-\theta)$

## Distribución Normal

La distribución normal es una distribución de probabilidad continua que se caracteriza por su forma de campana. La función de densidad de probabilidad (fdp) de esta distribución se puede expresar como:

$$p(x|\theta)=\frac{1}{\sqrt{2\pi\sigma^{2}}}e^{-\frac{1}{2\sigma^{2}}(x-\mu)^{2}}$$

$$p(x|\theta)=\left(\frac{1}{\sqrt{2\pi\sigma^{2}}}\exp\left(-\frac{x^{2}}{2\sigma^{2}}\right)\right)x\exp\left(\frac{\mu}{\sigma^{2}}x-\frac{\mu^{2}}{2\sigma^{2}}\right)$$

Donde:

- $h(x)=\left(\frac{1}{\sqrt{2\pi\sigma^{2}}}\exp\left(-\frac{x^2}{2\sigma^2}\right)\right)$

- $\eta(\theta)=\frac{\mu}{\sigma^{2}}$

- $t(x)=x$

- $a(\theta)=\frac{\mu^{2}}{2\sigma^{2}}$

## Distribución Poisson

La distribución Poisson es una distribución de probabilidad discreta que se utiliza para modelar el número de eventos que ocurren en un intervalo de tiempo o espacio fijo. La fmp de esta distribución se puede expresar como:

$$p(x|\theta)=\frac{\theta^{x}}{x!}e^{-\theta}; x = 0,1,2,...$$

$$p(x|\theta)=\frac{1}{x!}\exp\left(\log(\theta)x-\theta\right)$$

Donde:

- $h(x)=\frac{1}{x!}$

- $\eta(\theta)=\log(\theta)$

- $t(x)=x$

- $a(\theta)=\theta$

# Problema 2

La universidad de California Irvine (UCI) tiene un repositorio de datos de ejemplo para el uso de machine learning y aprendizaje estadístico. Uno de los conjuntos de datos es el denominado *Heart Disease*, su descripción detallada se encuentra en el URL a continuación: [https://archive.ics.uci.edu/dataset/45/heart+disease](https://archive.ics.uci.edu/dataset/45/heart+disease)

Utilice los datos procesados disponibles en el enlace presentado a continuación para el desarrollo del ejercicio: [http://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.
 cleveland.data](http://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.
 cleveland.data)

Con el conjunto de datos completo, construya un modelo de regresión logístico con funciones de enlace logit **tomando como respuesta la presencia de la enfermedad cardíaca**, use las demás variables como explicativas en el modelo de regresión. Revise las URL dadas para la definición de cada una de las variables y note que debe obtener la variable respuesta categorizando una de las variables del conjunto de datos. Siga los siguientes pasos en la realización del ejercicio:

```{r}
# Datos
url <- "http://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data"
heart_data <- read.csv(url, header = FALSE)

# Nombre de las variables
colnames(heart_data) <- c("age", "sex", "cp", "trestbps", "chol", "fbs", "restecg", "thalach", "exang", "oldpeak", "slope", "ca", "thal", "num")

# Categorización de la variable respuesta
heart_data <- heart_data %>%
  mutate(num = ifelse(num %in% c(1,2,3,4), 1, 0))
```

## Literal 1

**Imputar datos:** El conjunto de datos tiene datos perdidos en algunas variables. Estos están notados con un "?". Impute los valores perdidos como la mediana de los datos para las variables correspondientes.

```{r}
# Imputación de datos con la mediana de cada columna
heart_data <- heart_data %>%
  mutate_all(~ifelse(. == "?", NA, .)) %>%
  mutate_all(as.numeric) %>%
  mutate_all(~replace(., is.na(.), median(., na.rm = TRUE)))

# Validación de valores nulos
sum(is.na(heart_data))
```

## Literal 2

**Revisar las distribuciones bivariadas:** Revise la distribución de la variable respuesta para cada una de las covariables categóricas de manera bivariada. ¿Observa algún inconveniente con alguna de las variables al hacer el análisis?

```{r warning=FALSE, fig.height=20, fig.width=20}
# Covariables categóricas
heart_data <- heart_data %>%
  mutate(sex = as.factor(sex),
         cp = as.factor(cp),
         fbs = as.factor(fbs),
         restecg = as.factor(restecg),
         exang = as.factor(exang),
         slope = as.factor(slope),
         ca = as.numeric(ca),
         thal = as.integer(thal)) %>%
  mutate(thal = as.factor(thal))

categoricas <- c("sex", "cp", "fbs", "restecg", "exang", "slope", "thal")

# Gráficos
par(mfrow = c(3, 3))

for (var in categoricas) {
  # Tabla de contingencia
  contingencia <- table(heart_data$num, heart_data[[var]])
  barplot(contingencia,
          beside = TRUE,
          legend = TRUE,
          xlab = var,
          cex.lab = 2.5,
          cex.axis = 1.5,
          cex.names = 1.5,
          legend.text = c("0: No enfermedad", "1: Enfermedad"),
          args.legend = list(cex = 2)
  )
}

```

El desbalance en las covariables categóricas como `sex`, `cp`, `fbs`, `restecg`, `exang` y `thal` señala un posible inconveniente en el análisis, donde ciertas categorías tienen un número significativamente mayor de observaciones que otras, lo que podría impactar en la precisión y el rendimiento de modelos posteriores.

Asimismo, la superposición en la distribución de categorías de variables como `cp` y `fbs` sugiere proporciones relativamente similares de individuos con y sin enfermedad cardíaca, lo que podría indicar que estas variables podrían tener una relación más débil o más compleja con el resultado. En el caso de `fbs`, aunque el nivel de azúcar en la sangre en ayunas es relevante para la salud cardíaca, pueden existir otros factores, como la dieta y el estilo de vida, que también influyen en la relación entre `fbs` y la enfermedad cardíaca. Por otro lado, en el caso de `cp`, la variabilidad en la presentación de síntomas indica que diferentes tipos de dolor en el pecho pueden ser experimentados tanto por individuos con enfermedad cardíaca como por aquellos sin ella, lo que complica la relación entre esta variable y el resultado. 

## Literal 3

**Modelo bivariado:** Calcule manualmente (como lo vimos en clase, a partir de la tabla de contingencia), los parámetros estimados de regresión logística considerando únicamente la variable `fbs` (glucemia en ayunas) y la variable respuesta. Verifique el resultado ajustanto el `glm` correspondiente.

```{r, warning=FALSE}
# Tabla de contingencia
contingencia <- table(heart_data$fbs, heart_data$num)
rownames(contingencia) <- c("Glucemia <= 120 mg/dl", "Glucemia > 120 mg/dl")
colnames(contingencia) <- c("No enfermedad", "Enfermedad")
contingencia

# Probabilidades
prob_enfermedad_no_fbs <- contingencia[1, 2] / sum(contingencia[1, ])
prob_enfermedad_no_fbs
prob_enfermedad_si_fbs <- contingencia[2, 2] / sum(contingencia[2, ])
prob_enfermedad_si_fbs

# odds
odds_enfermedad_no_fbs <- contingencia[1, 2] / contingencia[1, 1]
odds_enfermedad_no_fbs
odds_enfermedad_si_fbs <- contingencia[2, 2] / contingencia[2, 1]
odds_enfermedad_si_fbs

# odds ratio
odds_ratio_enfermedad_no_fbs <- odds_enfermedad_no_fbs / odds_enfermedad_si_fbs
odds_ratio_enfermedad_no_fbs
odds_ratio_enfermedad_si_fbs <- odds_enfermedad_si_fbs / odds_enfermedad_no_fbs
odds_ratio_enfermedad_si_fbs

# log odds ratio
log_odds_ratio_enfermedad_no_fbs <- log(odds_enfermedad_no_fbs)
log_odds_ratio_enfermedad_no_fbs
log_odds_ratio_enfermedad_si_fbs <- log(odds_enfermedad_si_fbs) 
log_odds_ratio_enfermedad_si_fbs
log_odds_ratio_enfermedad <- log(odds_enfermedad_si_fbs) - log(odds_enfermedad_no_fbs)
log_odds_ratio_enfermedad
```
Para personas con niveles de glucemia <= 120 mg/dl, la probabilidad de tener enfermedad cardíaca es aproximadamente 0.45, mientras que para aquellos con niveles de glucemia > 120 mg/dl, la probabilidad aumenta ligeramente, siendo aproximadamente 0.48. **Estas probabilidades sugieren que puede haber más o menos la misma probabilidad de tener o no la enfermedad en presencia de glucemia > 120 mg/dl o de glucemia <= 120 mg/dl**. 

Los odds de tener enfermedad cardíaca muestran valores similares según los niveles de glucemia. Para personas con niveles de glucemia <= 120 mg/dl, el odds de tener enfermedad cardíaca es aproximadamente 0.83. Para aquellos con niveles de glucemia > 120 mg/dl, el odds es a aproximadamente 0.95. **Al igual que con las probabilidades, los odds cercanos a 1 sugieren que puede haber mas o menos la misma probabilidad de tener o no la enfermedad en los dos niveles de glucemia.**

Por otra parte, el odds ratio de tener enfermedad cardíaca para personas con niveles de glucemia > 120 mg/dl en comparación con aquellos con niveles de glucemia <= 120 mg/dl es aproximadamente 1.15. Mientras que el odds ratio de tener enfermedad cardíaca con niveles de glucemia <= 120 mg/dl en comparación con aquellos con niveles de glucemia > 120 mg/dl es de aproximadamente 0.86. **Los valores de estos odds ratio, al ser cercanos a 1, sugieren que la covariable `fbs` puede no ser informativa (da lo mismo en termino de odds de enfermedad).**

```{r}
# Modelo bivariado
logistic_model <- glm(num ~ fbs, data = heart_data, family = binomial)
summary(logistic_model)$coefficients
```

- **Intercepto**: El *odds* (en escala logarítmica) de enfermedad cuando una persona tiene una glucemia <= 120 mg/dl es de -0.18. 
- **Pendiente**: En presencia de glucemia > 120 mg/dl aumenta (en escala logarítmica) los oods de enfermedad en 0.14.

En general, el modelo bivariado indica que la covariable `fbs` no tiene un impacto significativo para predecir la enfermedad cardíaca. Esto de acuerdo con el análisis que se realizó manualmente, donde se observó que los odds ratio son cercanos a 1 y, en el modelo ajustado, donde el coeficiente asociado a esta variable no es significativo (p > 0.05).

## Literal 4

**Modelo multivariado:** Ajuste un nuevo modelo con todas las variables. ¿Cuáles variables son significativas mediante el test de Wald? ¿Cuáles no lo son?

```{r}
# Modelo multivariado
logistic_model_multivariable <- glm(num ~ ., data = heart_data, family = binomial)
printCoefmat(coef(summary(logistic_model_multivariable)))
```

En el modelo multivariado ajustado, se observa que tanto el intercepto como las variables: `sex1`, `cp4`,`trestbps`, `slope2`, `ca` y `thal7`, son significativas según el test de Wald,  con valores p < 0.05, lo cual indica que es poco probable que los coeficientes asociados a estas variables sean iguales a cero por casualidad. Por el contrario, las variables:`age`, `cp2`, `cp3`, `chol`, `fbs1`,`restecg1`,`restecg2`, `thalach`, `exang1`, `oldpeak`, `slope3` y `thal6`, no son significativas con valores p > 0.05, lo cual sugiere que no hay evidencia suficiente para rechazar la hipótesis nula de que los coeficientes asociados a estas variables son iguales a cero.

## Literal 5

**Visualización de probabilidades predichas bajo modelo multivariado:** Usando el modelo del punto anterior, encuentre las probabilidades de presentar enfermedad cardíaca y visualícelas junto a la variable respuesta. ¿Describe el modelo la presencia de enfermedad cardíaca?

```{r warning=FALSE, message=FALSE}
# Probabilidades predichas
heart_data <- heart_data %>%
  mutate(prob_pred = predict(logistic_model_multivariable, type = "response"))

# Gráfico
ggplot(heart_data, aes(x = prob_pred, y = num)) +
  geom_point(aes(color = factor(num))) +
  geom_smooth(method = "glm", method.args = list(family = "binomial"), se = FALSE) +
  labs(x = "Probabilidad predicha",
       y = "Enfermedad cardíaca") +
  theme(legend.position = "none") +
  scale_color_manual(values = c("0" = "black", "1" = "gray"))
```

El modelo multivariado describe la presencia de enfermedad cardíaca en este conjunto de datos. Los puntos negros (ausencia de enfermedad cardíaca) se concentran principalmente en la región inferior izquierda del gráfico, donde las probabilidades predichas son bajas, mientras que los puntos grises (presencia de enfermedad cardíaca) se concentran principalmente en la región superior derecha del gráfico, donde las probabilidades predichas son altas. Esto indica que el modelo es capaz de diferenciar entre los casos de enfermedad cardíaca presente y ausente. La curva de regresión logística aumenta gradualmente a medida que aumenta la probabilidad predicha, lo que indica que el modelo predice una mayor probabilidad de enfermedad cardíaca a medida que aumenta la probabilidad predicha.

# Problema 3

El conjunto de datos `ADD-taller03.xlsx` contiene la predicción de incumplimiento de pago de tarjeta de crédito bajo dos modelos logísticos diferentes para un total de 9080 clientes. Se cuenta además con la variable de incumplimiento observada al finalizar el periodo. ¿Cuál de los dos modelos logísticos tiene mayor poder de predicción? Explique con fundamento estadístico su resultado.

```{r}
# Datos
taller_data <- read_excel("data/AAD-taller03.xlsx")

# Conteo de casos positivos y negativos en incumplimiento
table(taller_data$Incumplimiento)
```

La variable `Incumplimiento` registra 4.450 casos negativos (0), lo que  equivale al 49,2% del total, y 4.630 casos positivos (1), representa el 50,8%. Esta distribución indica un equilibrio general con una leve inclinación hacia los casos positivos

A continuación, se procede a evaluar el poder de predicción de los dos modelos logísticos A y B, considerando la curva ROC y el área bajo la curva (AUC) para cada uno de los modelos.

```{r fig.height=6, fig.width=12}
# Modelo Logístico A
pred1 <- prediction(taller_data$ScoreLogisticoA, taller_data$Incumplimiento)
perf1 <- performance(pred1, "tpr", "fpr")

# Modelo Logístico B
pred2 <- prediction(taller_data$ScoreLogisticoB, taller_data$Incumplimiento)
perf2 <- performance(pred2, "tpr", "fpr")

# Curvas ROC
par(mfrow = c(1, 2))
plot(perf1, colorize = FALSE, main = "Modelo Logístico A")
plot(perf2, colorize = FALSE, main = "Modelo Logístico B")

# AUC
## Modelo Logístico A
auc1 <- format(performance(pred1, "auc")@y.values[[1]], digits = 2)
auc1

## Modelo Logístico B
auc2 <- format(performance(pred2, "auc")@y.values[[1]], digits = 2)
auc2
```

El **modelo logístico A** supera al modelo logístico B en términos de sensibilidad y especificidad, lo que se comprueba mediante sus áreas bajo la curva ROC **(AUC) de 0,61** y 0,32, respectivamente. Estadísticamente, el modelo A presenta un mejor poder de predicción debido a su mayor AUC.

Sin embargo, es importante destacar que, aunque el modelo A tiene un mejor rendimiento, aún se considera moderado en cuanto a su poder predictivo. Según [@bib02], una curva ROC ideal se ubicaría lo más cerca posible de la esquina superior izquierda, indicando un clasificador con alta tasa de recuperación (TFR) y baja tasa de falsos positivos (FPR). En este caso, el modelo A, con un AUC cercano a 0,5, se podría considerar algo mejor que un clasificador aleatorio, pero no un clasificador ideal.

# Problema 4

Repita el problema 2, pero en lugar de imputar los datos mediante la mediana en el literal 1, utilice el algoritmo EM.

```{r}
# Datos
url <- "http://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data"
heart_data <- read.csv(url, header = FALSE)

# Nombre de las variables
colnames(heart_data) <- c("age", "sex", "cp", "trestbps", "chol", "fbs", "restecg", "thalach", "exang", "oldpeak", "slope", "ca", "thal", "num")

# Categorización de la variable respuesta
heart_data <- heart_data %>%
  mutate(num = ifelse(num %in% c(1,2,3,4), 1, 0))
```

## Literal 1

**Imputar datos:** El conjunto de datos tiene datos perdidos en algunas variables. Estos están notados con un "?". Impute los valores perdidos utilizando el algoritmo EM.

```{r}
# Valores nulos
colSums(heart_data == "?")

# Frecuencia de valores en las variables 'ca' y 'thal'
table(heart_data$ca)
table(heart_data$thal)
```

Dado que se identificaron valores nulos en las variables `ca` y `thal`, de tipo `Integer` y `Categorical` respectivamente, se procede a imputar los valores nulos utilizando el algoritmo EM (*Expectation-Maximization*, por sus siglas en inglés). Este método permite capturar la estructura de los datos faltantes. De acuerdo con la documentación de la librería `mice` [@bib03], existen varios métodos a través de los cuales pueden imputarse los valores nulos. La aplicación de estos métodos dependerá de la naturaleza de los datos y su tipo de escala (factor, numérica). En el caso de la variable `ca`, se aplicará el método `pmm` (*Predictive Mean Matching*) y para la variable `thal` se utilizará el método `polyreg` (*Polytomous Regression*).


```{r warning=FALSE, message=FALSE}
# Valores "?" a NA
heart_data <- heart_data %>%
  mutate_all(~ifelse(. == "?", NA, .)) %>%
  mutate(ca = as.numeric(ca), thal = as.integer(thal)) %>%
  mutate(thal = as.factor(thal))

# Definir el método de imputación para cada variable
meth <- make.method(heart_data)
meth[c("ca")] <- "pmm"
meth[c("thal")] <- "polyreg"

# Imputar los datos faltantes utilizando el algoritmo EM
imp <- mice(heart_data, method = meth, seed = 22112)
heart_data <- complete(imp)
```

>**Bajo esta imputación, no se observaron cambios relevantes sobre los demás literales del problema 2. No obstante, se incluyen los códigos correspondientes, pero sin su interpretación.**

## Literal 2

**Revisar las distribuciones bivariadas:** Revise la distribución de la variable respuesta para cada una de las covariables categóricas de manera bivariada. 

```{r warning=FALSE, fig.height=20, fig.width=20}
# Covariables categóricas
heart_data <- heart_data %>%
  mutate(sex = as.factor(sex),
         cp = as.factor(cp),
         fbs = as.factor(fbs),
         restecg = as.factor(restecg),
         exang = as.factor(exang),
         slope = as.factor(slope))

categoricas <- c("sex", "cp", "fbs", "restecg", "exang", "slope", "thal")

# Gráficos
par(mfrow = c(3, 3))

for (var in categoricas) {
  # Tabla de contingencia
  contingencia <- table(heart_data$num, heart_data[[var]])
  barplot(contingencia,
          beside = TRUE,
          legend = TRUE,
          xlab = var,
          cex.lab = 2.5,
          cex.axis = 1.5,
          cex.names = 1.5,
          legend.text = c("0: No enfermedad", "1: Enfermedad"),
          args.legend = list(cex = 2)
  )
}
```

## Literal 3

**Modelo bivariado:** Calcule manualmente (como lo vimos en clase, a partir de la tabla de contingencia), los parámetros estimados de regresión logística considerando únicamente la variable `fbs` (glucemia en ayunas) y la variable respuesta. Verifique el resultado ajustanto el `glm` correspondiente.

```{r, warning=FALSE}
# Tabla de contingencia
contingencia <- table(heart_data$fbs, heart_data$num)
rownames(contingencia) <- c("Glucemia <= 120 mg/dl", "Glucemia > 120 mg/dl")
colnames(contingencia) <- c("No enfermedad", "Enfermedad")
contingencia

# Probabilidades
prob_enfermedad_no_fbs <- contingencia[1, 2] / sum(contingencia[1, ])
prob_enfermedad_no_fbs
prob_enfermedad_si_fbs <- contingencia[2, 2] / sum(contingencia[2, ])
prob_enfermedad_si_fbs

# odds
odds_enfermedad_no_fbs <- contingencia[1, 2] / contingencia[1, 1]
odds_enfermedad_no_fbs
odds_enfermedad_si_fbs <- contingencia[2, 2] / contingencia[2, 1]
odds_enfermedad_si_fbs

# odds ratio
odds_ratio_enfermedad_no_fbs <- odds_enfermedad_no_fbs / odds_enfermedad_si_fbs
odds_ratio_enfermedad_no_fbs
odds_ratio_enfermedad_si_fbs <- odds_enfermedad_si_fbs / odds_enfermedad_no_fbs
odds_ratio_enfermedad_si_fbs

# log odds ratio
log_odds_ratio_enfermedad_no_fbs <- log(odds_enfermedad_no_fbs)
log_odds_ratio_enfermedad_no_fbs
log_odds_ratio_enfermedad_si_fbs <- log(odds_enfermedad_si_fbs) 
log_odds_ratio_enfermedad_si_fbs
log_odds_ratio_enfermedad <- log(odds_enfermedad_si_fbs) - log(odds_enfermedad_no_fbs)
log_odds_ratio_enfermedad
```


```{r}
# Modelo bivariado
logistic_model <- glm(num ~ fbs, data = heart_data, family = binomial)
summary(logistic_model)$coefficients
```

## Literal 4

**Modelo multivariado:** Ajuste un nuevo modelo con todas las variables. ¿Cuáles variables son significativas mediante el test de Wald? ¿Cuáles no lo son?

```{r}
# Modelo multivariado
logistic_model_multivariable <- glm(num ~ ., data = heart_data, family = binomial)
printCoefmat(coef(summary(logistic_model_multivariable)))
```

## Literal 5

**Visualización de probabilidades predichas bajo modelo multivariado:** Usando el modelo del punto anterior, encuentre las probabilidades de presentar enfermedad cardíaca y visualícelas junto a la variable respuesta. ¿Describe el modelo la presencia de enfermedad cardíaca?

```{r warning=FALSE, message=FALSE}
# Probabilidades predichas
heart_data <- heart_data %>%
  mutate(prob_pred = predict(logistic_model_multivariable, type = "response"))

# Gráfico
ggplot(heart_data, aes(x = prob_pred, y = num)) +
  geom_point(aes(color = factor(num))) +
  geom_smooth(method = "glm", method.args = list(family = "binomial"), se = FALSE) +
  labs(x = "Probabilidad predicha",
       y = "Enfermedad cardíaca") +
  theme(legend.position = "none") +
  scale_color_manual(values = c("0" = "black", "1" = "gray"))
```

# Referencias