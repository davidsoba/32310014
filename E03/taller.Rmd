---
title: "Taller 3"
subtitle: "Análisis Avanzado de Datos"
author: "Geraldine Home Saenz - Jose David Soba Loaiza"
date: "2024-05-17"
output: rmdformats::downcute
bibliography: referencias.bib
link-citations: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message=FALSE, warning=FALSE}
# Librerías
library(tidyverse)
library(readxl)
library(ROCR)
library(mice)
```

# Problema 1

Una familia de distribuciones $P_\theta$ con $\theta \in \Theta$ pertenece a la familia exponencial de distribuciones si si fmp/fdp puede escribirse como:

$$p(x|\eta)=h(x)\exp\left(\eta(\theta)t(x)-a(\theta)\right)$$

Para funciones reales $h(x)$, $a(\theta)$ y $t(x)$. Muestre que tanto la distribución Bernoulli (utilizada para la regresión logística), la distribución normal (utilizada en la regresión lineal) y la distribución Poisson (utilizada en la regresión Poisson sobre conteos) pertenece a esta familia de distribuciones.

Tomado de: [@bib01].

## Distribución Bernoulli

La distribución Bernoulli es una distribución de probabilidad discreta que toma el valor 1 con probabilidad $\theta$ y el valor $0$ con probabilidad $1-\theta$. La función de masa de probabilidad (fmp) de esta distribución se puede expresar como:

$$p(x|\theta)=\binom{n}{x}\theta^x(1-\theta)^{n-x}; x = 0,1,...,n$$

$$p(x|\theta)=\binom{n}{x}\exp\left(log\left(\frac{\theta}{1-\theta}\right)x+nlog(1-\theta)\right)$$

Donde:

- $h(x)=\binom{n}{x}$

- $\eta(\theta)=log\left(\frac{\theta}{1-\theta}\right)$

- $t(x)=x$

- $a(\theta)=nlog(1-\theta)$

## Distribución Normal

La distribución normal es una distribución de probabilidad continua que se caracteriza por su forma de campana. La función de densidad de probabilidad (fdp) de esta distribución se puede expresar como:

$$p(x|\theta)=\frac{1}{\sqrt{2\pi\sigma^{2}}}e^{-\frac{1}{2\sigma^{2}}(x-\mu)^{2}}$$

$$p(x|\theta)=\left(\frac{1}{\sqrt{2\pi\sigma^{2}}}\exp\left(-\frac{x^{2}}{2\sigma^{2}}\right)\right)x\exp\left(\frac{\mu}{\sigma^{2}}x-\frac{\mu^{2}}{2\sigma^{2}}\right)$$

Donde:

- $h(x)=\left(\frac{1}{\sqrt{2\pi\sigma^{2}}}\exp\left(-\frac{x^2}{2\sigma^2}\right)\right)$

- $\eta(\theta)=\frac{\mu}{\sigma^{2}}$

- $t(x)=x$

- $a(\theta)=\frac{\mu^{2}}{2\sigma^{2}}$

## Distribución Poisson

La distribución Poisson es una distribución de probabilidad discreta que se utiliza para modelar el número de eventos que ocurren en un intervalo de tiempo o espacio fijo. La fmp de esta distribución se puede expresar como:

$$p(x|\theta)=\frac{\theta^{x}}{x!}e^{-\theta}; x = 0,1,2,...$$

$$p(x|\theta)=\frac{1}{x!}\exp\left(\log(\theta)x-\theta\right)$$

Donde:

- $h(x)=\frac{1}{x!}$

- $\eta(\theta)=\log(\theta)$

- $t(x)=x$

- $a(\theta)=\theta$

# Problema 2

La universidad de California Irvine (UCI) tiene un repositorio de datos de ejemplo para el uso de machine learning y aprendizaje estadístico. Uno de los conjuntos de datos es el denominado *Heart Disease*, su descripción detallada se encuentra en el URL a continuación: [https://archive.ics.uci.edu/dataset/45/heart+disease](https://archive.ics.uci.edu/dataset/45/heart+disease)

Utilice los datos procesados disponibles en el enlace presentado a continuación para el desarrollo del ejercicio: [http://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.
 cleveland.data](http://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.
 cleveland.data)

Con el conjunto de datos completo, construya un modelo de regresión logístico con funciones de enlace logit **tomando como respuesta la presencia de la enfermedad cardíaca**, use las demás variables como explicativas en el modelo de regresión. Revise las URL dadas para la definición de cada una de las variables y note que debe obtener la variable respuesta categorizando una de las variables del conjunto de datos. Siga los siguientes pasos en la realización del ejercicio:

```{r}
# Datos
url <- "http://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data"
heart_data <- read.csv(url, header = FALSE)

# Nombre de las variables
colnames(heart_data) <- c("age", "sex", "cp", "trestbps", "chol", "fbs", "restecg", "thalach", "exang", "oldpeak", "slope", "ca", "thal", "num")

# Categorización de la variable respuesta
heart_data <- heart_data %>%
  mutate(num = ifelse(num %in% c(1,2,3,4), 1, 0))
```

## Literal 1

**Imputar datos:** El conjunto de datos tiene datos perdidos en algunas variables. Estos están notados con un "?". Impute los valores perdidos como la mediana de los datos para las variables correspondientes.

```{r}
# Imputación de datos con la mediana de cada columna
heart_data <- heart_data %>%
  mutate_all(~ifelse(. == "?", NA, .)) %>%
  mutate_all(as.numeric) %>%
  mutate_all(~replace(., is.na(.), median(., na.rm = TRUE)))

# Validación de valores nulos
sum(is.na(heart_data))
```

## Literal 2

**Revisar las distribuciones bivariadas:** Revise la distribución de la variable respuesta para cada una de las covariables categóricas de manera bivariada. ¿Observa algún inconveniente con alguna de las variables al hacer el análisis?

```{r warning=FALSE, fig.height=20, fig.width=20}
# Covariables categóricas
heart_data <- heart_data %>%
  mutate(sex = as.factor(sex),
         cp = as.factor(cp),
         fbs = as.factor(fbs),
         restecg = as.factor(restecg),
         exang = as.factor(exang),
         slope = as.factor(slope),
         ca = as.numeric(ca),
         thal = as.integer(thal)) %>%
  mutate(thal = as.factor(thal))

categoricas <- c("sex", "cp", "fbs", "restecg", "exang", "slope", "thal")

# Gráficos
par(mfrow = c(3, 3))

for (var in categoricas) {
  # Tabla de contingencia
  contingencia <- table(heart_data$num, heart_data[[var]])
  barplot(contingencia,
          beside = TRUE,
          legend = TRUE,
          xlab = var,
          cex.lab = 2.5,
          cex.axis = 1.5,
          cex.names = 1.5,
          legend.text = c("0: No enfermedad", "1: Enfermedad"),
          args.legend = list(cex = 2)
  )
}
```

En primer lugar, en la variable "sex", se destaca una proporción significativamente más alta de hombres (1) en comparación con mujeres (0) en el conjunto de datos. Además, al examinar la variable "cp" (tipo de dolor en el pecho), se encuentra que la mayoría de los pacientes tienen dolor de pecho no anginal (valor 3) o son asintomáticos (valor 4).

En cuanto a las variables relacionadas con mediciones médicas, la mayoría de los pacientes tienen niveles de azúcar en sangre en ayunas menores o iguales a 120 mg/dl (valor 0) en la variable "fbs". En la variable "restecg" (resultados electrocardiográficos en reposo), la mayoría de los pacientes muestran resultados normales (valor 0), lo que sugiere una función cardíaca típica en reposo.

Sin embargo, hay algunas consideraciones importantes que se deben tener en cuenta. Por ejemplo, en la variable "exang" (angina inducida por el ejercicio), se observa una cantidad considerable de pacientes que no experimentan angina durante el ejercicio (valor 0). Además, en la variable "slope" (pendiente del segmento ST durante el ejercicio), la mayoría de los pacientes muestran una pendiente ascendente del segmento ST durante el ejercicio (valor 1). 

## Literal 3

**Modelo bivariado:** Calcule manualmente (como lo vimos en clase, a partir de la tabla de contingencia), los parámetros estimados de regresión logística considerando únicamente la variable `fbs` (glucemia en ayunas) y la variable respuesta. Verifique el resultado ajustanto el `glm` correspondiente.

```{r, warning=FALSE}
# Tabla de contingencia
contingencia <- table(heart_data$fbs, heart_data$num)
rownames(contingencia) <- c("Glucemia <= 120 mg/dl", "Glucemia > 120 mg/dl")
colnames(contingencia) <- c("No enfermedad", "Enfermedad")
contingencia

# Probabilidades
prob_enfermedad_no_fbs <- contingencia[1, 2] / sum(contingencia[1, ])
prob_enfermedad_si_fbs <- contingencia[2, 2] / sum(contingencia[2, ])

# odds
odds_enfermedad_no_fbs <- contingencia[1, 2] / contingencia[1, 1]
odds_enfermedad_si_fbs <- contingencia[2, 2] / contingencia[2, 1]
odd_ratio_enfermedad <- odds_enfermedad_no_fbs / odds_enfermedad_si_fbs
log_odd_ratio_enfermedad <- log(odds_enfermedad_no_fbs) - log(odds_enfermedad_si_fbs)
```


```{r}
# Modelo bivariado
logit_model <- glm(num ~ fbs, data = heart_data, family = binomial)
summary(logit_model)$coefficients
```

## Literal 4

**Modelo multivariado:** Ajuste un nuevo modelo con todas las variables. ¿Cuáles variables son significativas mediante el test de Wald? ¿Cuáles no lo son?

```{r}
# Modelo multivariado
logit_model_multivariable <- glm(num ~ ., data = heart_data, family = binomial)
printCoefmat(coef(summary(logit_model_multivariable)))
```

## Literal 5

**Visualización de probabilidades predichas bajo modelo multivariado:** Usando el modelo del punto anterior, encuentre las probabilidades de presentar enfermedad cardíaca y visualícelas junto a la variable respuesta. ¿Describe el modelo la presencia de enfermedad cardíaca?

```{r warning=FALSE, message=FALSE}
# Probabilidades predichas
heart_data <- heart_data %>%
  mutate(prob_pred = predict(logit_model_multivariable, type = "response"))

# Gráfico
ggplot(heart_data, aes(x = prob_pred, y = num)) +
  geom_point(aes(color = factor(num))) +
  geom_smooth(method = "glm", method.args = list(family = "binomial"), se = FALSE) +
  labs(x = "Probabilidad predicha",
       y = "Enfermedad cardíaca") +
  theme(legend.position = "none") +
  scale_color_manual(values = c("0" = "black", "1" = "gray"))
```

# Problema 3

El conjunto de datos `ADD-taller03.xlsx` contiene la predicción de incumplimiento de pago de tarjeta de crédito bajo dos modelos logísticos diferentes para un total de 9080 clientes. Se cuenta además con la variable de incumplimiento observada al finalizar el periodo. ¿Cuál de los dos modelos logísticos tiene mayor poder de predicción? Explique con fundamento estadístico su resultado.

```{r}
# Datos
taller_data <- read_excel("data/AAD-taller03.xlsx")

# Conteo de casos positivos y negativos en incumplimiento
table(taller_data$Incumplimiento)
```

La variable `Incumplimiento` registra 4.450 casos negativos (0), equivalentes al 49,2% del total, y 4.630 casos positivos (1), que representan el 50,8%. Esta distribución muestra un equilibrio general con una leve inclinación hacia los casos positivos

A continuación, se procede a evaluar el poder de predicción de los dos modelos logísticos A y B teniendo en cuenta la curva ROC y el área bajo la curva (AUC) para cada uno de los modelos.

```{r fig.height=6, fig.width=12}
# Modelo Logístico A
pred1 <- prediction(taller_data$ScoreLogisticoA, taller_data$Incumplimiento)
perf1 <- performance(pred1, "tpr", "fpr")

# Modelo Logístico B
pred2 <- prediction(taller_data$ScoreLogisticoB, taller_data$Incumplimiento)
perf2 <- performance(pred2, "tpr", "fpr")

# Curvas ROC
par(mfrow = c(1, 2))
plot(perf1, colorize = FALSE, main = "Modelo Logístico A")
plot(perf2, colorize = FALSE, main = "Modelo Logístico B")

# AUC
## Modelo Logístico A
auc1 <- format(performance(pred1, "auc")@y.values[[1]], digits = 2)
auc1

## Modelo Logístico B
auc2 <- format(performance(pred2, "auc")@y.values[[1]], digits = 2)
auc2
```

El **modelo logístico A** supera al modelo logístico B en términos de sensibilidad y especificidad, lo que se comprueba mediante sus áreas bajo la curva ROC (AUC) de 0,61 y 0,32, respectivamente. Estadísticamente, el modelo A presenta un mejor poder de predicción debido a su mayor AUC.

Sin embargo, cabe destacar que, si bien el modelo A tiene un mejor rendimiento, aún se considera moderado en cuanto a su poder predictivo. Según [@bib02], una curva ROC ideal se ubicaría lo más cerca posible de la esquina superior izquierda, indicando un clasificador con alta tasa de recuperación (TFR) y baja tasa de falsos positivos (FPR). En este caso, el modelo A, con un AUC cercano a 0,5, se podría considerar algo mejor que un clasificador aleatorio, pero no un clasificador ideal.

# Problema 4

Repita el problema 2, pero en lugar de imputar los datos mediante la mediana en el literal 1, utilice el algoritmo EM.

```{r}
# Datos
url <- "http://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data"
heart_data <- read.csv(url, header = FALSE)

# Nombre de las variables
colnames(heart_data) <- c("age", "sex", "cp", "trestbps", "chol", "fbs", "restecg", "thalach", "exang", "oldpeak", "slope", "ca", "thal", "num")

# Categorización de la variable respuesta
heart_data <- heart_data %>%
  mutate(num = ifelse(num %in% c(1,2,3,4), 1, 0))
```

## Literal 1

**Imputar datos:** El conjunto de datos tiene datos perdidos en algunas variables. Estos están notados con un "?". Impute los valores perdidos utilizando el algoritmo EM.

```{r}
# Valores nulos
colSums(heart_data == "?")

# Frecuencia de valores en las variables 'ca' y 'thal'
table(heart_data$ca)
table(heart_data$thal)
```

Dado que los valores nulos se encuentran en las variables `ca` y `thal`, de tipo `integer` y `Categorical` respectivamente, se procede a imputar los valores nulos utilizando el algoritmo EM (*Expectation-Maximization*, por sus siglas en inglés) bajo un método que permita capturar la estructura de los mismos. De acuerdo con la documentación de la librería `mice` [@bib03], existen varios métodos a través de los cuales pueden imputarse los valores nulos. La aplicación de estos métodos dependerá de la naturaleza de los datos y su tipo de escala (factor, numérica). En el caso de la variable `ca`, se utilizará el método `pmm` (*Predictive Mean Matching*) y para la variable `thal` se utilizará el método `polyreg` (*Polytomous Regression*).


```{r warning=FALSE, message=FALSE}
# Valores "?" a NA
heart_data <- heart_data %>%
  mutate_all(~ifelse(. == "?", NA, .)) %>%
  mutate(ca = as.numeric(ca), thal = as.integer(thal)) %>%
  mutate(thal = as.factor(thal))

# Definir el método de imputación para cada variable
meth <- make.method(heart_data)
meth[c("ca")] <- "pmm"
meth[c("thal")] <- "polyreg"

# Imputar los datos faltantes utilizando el algoritmo EM
imp <- mice(heart_data, method = meth, seed = 22112)
heart_data <- complete(imp)
```

## Literal 2

**Revisar las distribuciones bivariadas:** Revise la distribución de la variable respuesta para cada una de las covariables categóricas de manera bivariada. ¿Observa algún inconveniente con alguna de las variables al hacer el análisis?

```{r warning=FALSE, fig.height=20, fig.width=20}
# Covariables categóricas
heart_data <- heart_data %>%
  mutate(sex = as.factor(sex),
         cp = as.factor(cp),
         fbs = as.factor(fbs),
         restecg = as.factor(restecg),
         exang = as.factor(exang),
         slope = as.factor(slope))

categoricas <- c("sex", "cp", "fbs", "restecg", "exang", "slope", "thal")

# Gráficos
par(mfrow = c(3, 3))

for (var in categoricas) {
  # Tabla de contingencia
  contingencia <- table(heart_data$num, heart_data[[var]])
  barplot(contingencia,
          beside = TRUE,
          legend = TRUE,
          xlab = var,
          cex.lab = 2.5,
          cex.axis = 1.5,
          cex.names = 1.5,
          legend.text = c("0: No enfermedad", "1: Enfermedad"),
          args.legend = list(cex = 2)
  )
}
```

## Literal 3

**Modelo bivariado:** Calcule manualmente (como lo vimos en clase, a partir de la tabla de contingencia), los parámetros estimados de regresión logística considerando únicamente la variable `fbs` (glucemia en ayunas) y la variable respuesta. Verifique el resultado ajustanto el `glm` correspondiente.

```{r, warning=FALSE}
# Tabla de contingencia
contingencia <- table(heart_data$fbs, heart_data$num)
rownames(contingencia) <- c("Glucemia <= 120 mg/dl", "Glucemia > 120 mg/dl")
colnames(contingencia) <- c("No enfermedad", "Enfermedad")
contingencia

# Probabilidades
prob_enfermedad_no_fbs <- contingencia[1, 2] / sum(contingencia[1, ])
prob_enfermedad_si_fbs <- contingencia[2, 2] / sum(contingencia[2, ])

# odds
odds_enfermedad_no_fbs <- contingencia[1, 2] / contingencia[1, 1]
odds_enfermedad_si_fbs <- contingencia[2, 2] / contingencia[2, 1]
odd_ratio_enfermedad <- odds_enfermedad_no_fbs / odds_enfermedad_si_fbs
log_odd_ratio_enfermedad <- log(odds_enfermedad_no_fbs) - log(odds_enfermedad_si_fbs)
```


```{r}
# Modelo bivariado
logit_model <- glm(num ~ fbs, data = heart_data, family = binomial)
summary(logit_model)$coefficients
```

## Literal 4

**Modelo multivariado:** Ajuste un nuevo modelo con todas las variables. ¿Cuáles variables son significativas mediante el test de Wald? ¿Cuáles no lo son?

```{r}
# Modelo multivariado
logit_model_multivariable <- glm(num ~ ., data = heart_data, family = binomial)
printCoefmat(coef(summary(logit_model_multivariable)))
```

## Literal 5

**Visualización de probabilidades predichas bajo modelo multivariado:** Usando el modelo del punto anterior, encuentre las probabilidades de presentar enfermedad cardíaca y visualícelas junto a la variable respuesta. ¿Describe el modelo la presencia de enfermedad cardíaca?

```{r warning=FALSE, message=FALSE}
# Probabilidades predichas
heart_data <- heart_data %>%
  mutate(prob_pred = predict(logit_model_multivariable, type = "response"))

# Gráfico
ggplot(heart_data, aes(x = prob_pred, y = num)) +
  geom_point(aes(color = factor(num))) +
  geom_smooth(method = "glm", method.args = list(family = "binomial"), se = FALSE) +
  labs(x = "Probabilidad predicha",
       y = "Enfermedad cardíaca") +
  theme(legend.position = "none") +
  scale_color_manual(values = c("0" = "black", "1" = "gray"))
```

# Referencias