---
title: "Taller 2 - Splines de Regresión y Regresión Local"
subtitle: "Análisis Avanzado de Datos"
author: "Geraldine Home Saenz - Jose David Soba Loaiza"
date: "2024-04-24"
output: rmdformats::downcute
# bibliography: referencias.bib
# link-citations: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message=FALSE, warning=FALSE}
# Librerías
library(tidyverse)
library(ISLR2)
library(splines)
```

# Problema 1

El conjunto de datos Auto en la librería `ISLR2`, utilizado en clase, contiene la información del rendimiento y otras variables para un total de 392 vehículos. Como nos dimos cuenta, la relación entre dos de sus variables (`horsepower` y `mpg`) es resumida de manera parsimoniosa mediante un polinomio global de grado 2, sin embargo un *spline* suavizado (*smoothing spline*) parece dar un menor error de predicción. Por otra parte, determinar la ubicación y cantidad de *knots* en el *spline* de regresión (*regression spline*) fue un problema que desincentivó su uso. El método de validación externa utilizado para comparar los modelos fue **validación regular**.
 
## Pregunta 1

Separe aleatoriamente (pero guarde la semilla) su conjunto de datos en dos partes:
- Entrenamiento: 90% de los autos
- Prueba: 10% de los autos.

```{r, message=FALSE}
# Semilla
set.seed(123)

# Conjuntos de entrenamiento y prueba
Auto <- Auto
sample_size <- nrow(Auto)
train <- sample(sample_size, 0.9 * sample_size)
test <- seq(sample_size)[!seq(sample_size) %in% train]
```

## Pregunta 2

**Usando los datos de entrenamiento** Mediante validación cruzada en 10 *folds*, determine el número óptimo de *knots* para el problema de regresión *spline*. Considere como número de posible de *knots* 1,...,10, igualmente espaciados en el rango de la variable `horsepower`. ¿Qué modelo (es decir, cual valor de *knot* con k = 1,...,10) resulta en un menor ECM de predicción?

**Ayudas:**
- Puede ser conveniente definir los folds de manera aleatoria como `sample(1:10,n,replace=TRUE)` para facilitar la validación cruzada.

- Tiene que ajustar en cada fold los 10 posibles knots, y probar su error en el conjunto de prueba. Por lo tal, tendría un total de 100 errores externos al hacer validación cruzada: 10 por cada uno de los 10 posibles knots.

- `splines::bs` permite encontrar la base b-spline (aquella base "multiproposito" mencionada en clase) para usar en el problema de regresión.

- `splines::bs` en su argumento `Boundary.knots` permite definir los knots de frontera. Puede dejarlos unas unidades alejadas del rango para asegurar un ajuste apropiado, por ejemplo: `Boundary.knots = range(horsepower) + c(-5,+5)`.

```{r, message=FALSE, warning=FALSE}
# Validación cruzada
set.seed(123)
knots <- 1:10
folds <- sample(1:10, nrow(Auto), replace = TRUE)

# Error cuadrático medio
mse <- matrix(NA, nrow = 10, ncol = 10)
for (k in knots) {
  for (fold in 1:10) {
    train_idx <- which(folds != fold)
    test_idx <- which(folds == fold)
    
    # Ajuste del modelo
    fit <- lm(mpg ~ bs(horsepower, df = k, Boundary.knots = range(Auto$horsepower) + c(-5, +5)), data = Auto[train_idx, ])
    
    # Predicción
    pred <- predict(fit, newdata = Auto[test_idx, ])
    
    # Error cuadrático medio
    mse[k, fold] <- mean((Auto$mpg[test_idx] - pred)^2)
  }
}
# promedio de los ECM por cada fold
mse_mean_folds <- colMeans(mse)

# Fold óptimo
fold_opt <- which.min(mse_mean_folds)
fold_opt

# Knot óptimo
knot_opt <- which.min(mse[, fold_opt])
knot_opt
```

Para determinar el número óptimo de *knots* para el problema de regresión *spline* mediante validación cruzada en 10 *folds*, se realizaron ajustes de modelos para cada valor de *knots* (de 1 a 10) y se evaluó su rendimiento en términos de error cuadrático medio (ECM) en el conjunto de prueba. Luego, se calculó el promedio de los ECM por cada *fold*. **El *fold* óptimo es el número 8, y el *knot* óptimo que minimiza el ECM es el 8, también**. Esto implica que el modelo con 8 *knots* resulta en el menor ECM de predicción según la validación cruzada en 10 *folds*. 

## Pregunta 3

**Usando los datos de entrenamiento, determine el mejor modelo basado en base de funciones** Compare el poder de predicción de los modelos: polinomio grado 2 global, spline suavizado y del modelo de regresión spline óptimo (encontrado en el punto anterior) utilizando validación cruzada en 10 folds. ¿Cuál de los tres modelos seleccionaría basado en el ECM de predicción?

**Ayudas:**
- Tiene que ajustar en cada fold los 3 modelos, y probar su error en el conjunto de prueba. Por lo tanto, tendría un total de 30 errores externos al hacer validación cruzada: 10 por cada uno de los 3 modelos.

```{r, message=FALSE, warning=FALSE}
# Ajuste de modelos
set.seed(123)
# Modelo de polinomio grado 2 global
model1 <- lm(mpg ~ poly(horsepower, 2), data = Auto[train, ])

# Modelo de regresión spline suavizado
model2 <- smooth.spline(Auto$horsepower[train], Auto$mpg[train], cv = TRUE)

# Modelo de regresión spline óptimo
model3 <- lm(mpg ~ bs(horsepower, df = knot_opt, Boundary.knots = range(Auto$horsepower) + c(-5, +5)), data = Auto[train, ])

# Validación cruzada
folds <- sample(1:10, nrow(Auto), replace = TRUE)

# Error cuadrático medio
mse <- matrix(NA, nrow = 3, ncol = 10)

for (fold in 1:10) {
  test_idx <- which(folds == fold)
  
  # Predicciones
  pred1 <- predict(model1, newdata = Auto[test_idx, ])
  pred2 <- predict(model2, newdata = Auto[test_idx, ])
  pred3 <- predict(model3, newdata = Auto[test_idx, ])
  
  # Error cuadrático medio
  mse[1, fold] <- mean((Auto$mpg[test_idx] - pred1)^2)
  mse[2, fold] <- mean((Auto$mpg[test_idx] - pred2$y)^2)
  mse[3, fold] <- mean((Auto$mpg[test_idx] - pred3)^2)
}

# Mejor modelo
mse_mean <- rowMeans(mse)
mse_mean
best_model <- which.min(mse_mean)
best_model
```

Después de realizar la validación cruzada en 10 *folds* y calcular los ECM para cada uno de los tres modelos, los resultados son los siguientes:

 - Para el **modelo de polinomio grado 2 global**, el ECM promedio es aproximadamente 18.75.
 - Para el **modelo de spline suavizado**, el ECM promedio es aproximadamente 128.50.
 - Para el **modelo de regresión spline óptimo**, el ECM promedio es aproximadamente 18.04.

Basándonos en el ECM de predicción, el modelo seleccionado sería el *modelo de regresión spline óptimo*, ya que tiene el menor ECM promedio entre los tres modelos evaluados.

## Pregunta 4

**Usando los datos de entrenamiento, determine el mejor modelo basado en regresión local**. Determine la regresión polinomial local con kernel gaussiano que resulte en menor error de predicción: regresión de grado 1 o 2. Use el ancho de banda óptimo dado por defecto por la función `loess()`.

**Ayudas:**
- Es altamente recomendado utilizar `ksmooth` en lugar de `loess` para el estimador de Nadaraya–Watson, sin embargo esto dificulta el proceso de predicción de manera poco interesante. Considere únicamente los grados 1 y 2 en su decisión (note que esto ha sido cambiado en el cuerpo de la pregunta).

```{r, message=FALSE}
# Ajuste de modelos
set.seed(123)
# Regresión local de grado 1
model1 <- loess(mpg ~ horsepower, degree = 1, data = Auto[train, ])

# Regresión local de grado 2
model2 <- loess(mpg ~ horsepower, degree = 2, data = Auto[train, ])

# Validación cruzada
folds <- sample(1:10, nrow(Auto), replace = TRUE)

# Error cuadrático medio
mse <- matrix(NA, nrow = 2, ncol = 10)
for (fold in 1:10) {
    test_idx <- which(folds == fold)
    
    # Predicciones
    pred1 <- predict(model1, newdata = Auto[test_idx, ])
    pred2 <- predict(model2, newdata = Auto[test_idx, ])
    
    # Error cuadrático medio
    mse[1, fold] <- mean((Auto$mpg[test_idx] - pred1)^2)
    mse[2, fold] <- mean((Auto$mpg[test_idx] - pred2)^2)
}

# Mejor modelo
mse_mean <- rowMeans(mse)
mse_mean
best_model <- which.min(mse_mean)
best_model
```

Luego de ajustar los *modelos de regresión local de grado 1 y grado 2*, y realizar la validación cruzada en 10 *folds* para cada uno, los resultados son los siguientes:

 - Para la **regresión local de grado 1**, el ECM promedio es aproximadamente 18.64.
 - Para la **regresión local de grado 2**, el ECM promedio es aproximadamente 18.20.
 
Basándonos en el ECM de predicción, el modelo seleccionado sería la *regresión local de grado 2*, ya que tiene un ECM promedio ligeramente menor que la regresión local de grado 1. 

## Pregunta 5

**Usando los datos de entrenamiento y de prueba, determine el mejor de los tres paradigmas de modelamiento**. Ajuste el mejor modelo basado en base de funciones, el mejor modelo basado en regresión local y un polinomio global de grado dos con los datos de entrenamiento y calcule el ECM de prueba para cada modelo.

```{r, message=FALSE}
# Ajuste de modelos
set.seed(123)

# Mejor modelo basado en base de funciones
model1 <- lm(mpg ~ bs(horsepower, df = knot_opt, Boundary.knots = range(Auto$horsepower) + c(-5, +5)), data = Auto[train, ])

# Mejor modelo basado en regresión local
model2 <- loess(mpg ~ horsepower, degree = 2, data = Auto[train, ])

# Modelo de polinomio grado 2 global
model3 <- lm(mpg ~ poly(horsepower, 2), data = Auto[train, ])

# Validación cruzada
folds <- sample(1:10, nrow(Auto), replace = TRUE)

# Error cuadrático medio
mse <- matrix(NA, nrow = 3, ncol = 10)

for (fold in 1:10) {
  test_idx <- which(folds == fold)
  
  # Predicciones
  pred1 <- predict(model1, newdata = Auto[test_idx, ])
  pred2 <- predict(model2, newdata = Auto[test_idx, ])
  pred3 <- predict(model3, newdata = Auto[test_idx, ])
  
  # Error cuadrático medio
  mse[1, fold] <- mean((Auto$mpg[test_idx] - pred1)^2)
  mse[2, fold] <- mean((Auto$mpg[test_idx] - pred2)^2)
  mse[3, fold] <- mean((Auto$mpg[test_idx] - pred3)^2)
}

# Mejor modelo
mse_mean <- rowMeans(mse)
mse_mean
best_model <- which.min(mse_mean)
best_model
```

Después de ajustar los modelos y calcular el ECM en el conjunto de entrenamiento y de prueba para cada uno, los resultados son los siguientes:

 - El mejor modelo basado en **base de funciones** (regresión *spline* óptima), el ECM de prueba es aproximadamente 18.04.
 - El mejor modelo basado en **regresión local** (regresión local de grado 2), el ECM de prueba es aproximadamente 18.20.
 - El modelo de **polinomio global de grado 2**, el ECM de prueba es aproximadamente 18.75.
 
Basándonos en el ECM de prueba, el mejor modelo sería *basado en base de funciones*, es decir, la regresión *spline* óptima. Este modelo proporciona el menor error de predicción en el conjunto de prueba.

## Pregunta 6

Repita (1)-(5) un total de 10 veces de manera que en el paso (1) conforme una nueva muestra de validación cruzada, esto le permitirá obtener 10 ECM de prueba para cada paradigma de modelamiento. Grafique las tres distribuciones del ECM de prueba y responda ¿Cuál acercamiento seleccionaría basado en el ECM de predición: basado en base de funciones, basado en regresión local o polinomial global?.

```{r, message=FALSE}
# Función para ajustar modelos y calcular el ECM
aproach <- function(Auto, num_iter = 10) {

  # Vectores de almacenamiento
  mse_base_func <- numeric(num_iter)
  mse_local_reg <- numeric(num_iter)
  mse_glob_poly <- numeric(num_iter)

  # Iteraciones
  for (i in 1:num_iter) {
    set.seed(i)
    train_idx <- sample.int(nrow(Auto), 0.9 * nrow(Auto))
    test_idx <- seq(nrow(Auto))[!seq(nrow(Auto)) %in% train_idx]
    train <- Auto[train_idx, ]
    test <- Auto[test_idx, ]

    # Ajuste de modelos
    model_base_func <- lm(mpg ~ bs(horsepower, df = knot_opt, Boundary.knots = range(Auto$horsepower) + c(-5, +5)), data = train)
    model_local_reg <- loess(mpg ~ horsepower, degree = 2, data = train)
    model_glob_poly <- lm(mpg ~ poly(horsepower, 2), data = train)

    # Predicciones
    pred_base_func <- predict(model_base_func, newdata = test)
    pred_local_reg <- predict(model_local_reg, newdata = test)
    pred_glob_poly <- predict(model_glob_poly, newdata = test)

    # Error cuadrático medio
    mse_base_func[i] <- mean((test$mpg - pred_base_func)^2)
    mse_local_reg[i] <- mean((test$mpg - pred_local_reg)^2)
    mse_glob_poly[i] <- mean((test$mpg - pred_glob_poly)^2)
  }

  # Gráfico de la distribución del ECM de prueba en ggplot2
  df <- data.frame(
    mse = c(mse_base_func, mse_local_reg, mse_glob_poly),
    model = rep(c("Base de funciones", "Regresión local", "Polinomio global"), each = num_iter)) %>%
    mutate(model = factor(model, levels = c("Base de funciones", "Regresión local", "Polinomio global"))) %>%
    ggplot(aes(x = model, y = mse, fill = model)) +
    geom_boxplot(width = 0.2, color = "#2F4F4F", fill = "white") +
    geom_jitter(width = 0.1, alpha = 0.2) +
    labs(x = "Modelo", y = "ECM de prueba", title = "Comparación de acercamientos") +
    theme(legend.position = "none")

  print(df)

}

# Repetición de los pasos
set.seed(123)
aproach(Auto, 10)
```

# Problema 2

## Pregunta 7

En el contexto de análisis de datos funcionales se tiene una colección finita de observaciones ruidosas, donde para cada individuo, estas se asumen provenientes de una curva de dimensión infinita la cual es evaluada en puntos de un intervalo determinado. Para la i-ésima unidad estadística se tiene un conjunto de $n_i$ observaciones discretizadas $x_{i1},\dots,x_{ij},\dots,x_{in_i}$ de la función $x_i$ en los puntos $t_{i1}, \dots, t_{ij} , \dots, t_{in_i}$ con $x_{ij} \in R, t_{ij} \in T$ y $T$ un intervalo que representa el dominio sobre los reales donde se definen los datos funcionales.

**Escriba el estimador de Nadaraya–Watson para la i-ésima unidad estadística en $t$, es decir, $x(t)$**

$$\hat{x_i}(t) = \frac{\sum_{j=1}^{n_i} K\left(\frac{t-t_{ij}}{h}\right)x_{ij}}{\sum_{j=1}^{n_i} K\left(\frac{t-t_{ij}}{h}\right)}$$

Donde:

 - $\hat{x_i}(t)$ es la estimación de la función ${x}(t)$ para la i-ésima unidad estadística en el punto $t$.
 - ${n_i}$ es el número de observaciones para la i-ésima unidad estadística.  
 - ${x_i}$ es el valor observado para la i-ésima unidad estadística en el punto $t$.
 - $k$ es una función de kernel, que asigna pesos a las observaciones en función de su distancia a $t$.
 - $h$ es el ancho de banda, que controla el tamaño de la vecindad en $t$ considerada en la suavización.


## Pregunta 8

La centralidad de los datos funcionales se resume en la función media $µ$, la cual puede interpretarse en cada valor $t \in T$ como el valor promedio de la función aleatoria subyacente en $t, µ(t)$. Fíjese que el estimador de Nadarya–Watson puede extenderse a más de una unidad estadística, resultando en $t$ como un promedio ponderado de las observaciones cercanas para todas las observaciones $x_{ij}$:

**Escriba el estimador de Nadaraya–Watson para la función media en $t$, es decir, $\hat{\mu}(t)$. Note que todos los datos discretizados son utilizados en la estimación de la función media**

$$\hat{\mu}(t) = \frac{\sum_{i=1}^N \sum_{j=1}^{n_i} K\left(\frac{t-t_{ij}}{h}\right)x_{ij}}{\sum_{i=1}^N \sum_{j=1}^{n_i} K\left(\frac{t-t_{ij}}{h}\right)}$$

Donde:

 - $\hat{\mu}(t)$ es la estimación de la función media en el punto  $t$.
 - $N$ es el número total de unidades estadísticas.

